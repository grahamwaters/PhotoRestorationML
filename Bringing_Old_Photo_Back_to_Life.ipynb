{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Bringing Old Photo Back to Life.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/icehelmetminer/PhotoRestorationML/blob/main/Bringing_Old_Photo_Back_to_Life.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vkkr1Sq6t2lM"
      },
      "source": [
        "#◢ Bringing Old Photos Back to Life"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypb6kal06Tb1"
      },
      "source": [
        "This is a reference implementation of our CVPR 2020 paper [1], which  revives an old photo to modern style. Should you be making use of our work, please cite our paper [1]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwXBx7z6rfXK"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#◢ Verify Runtime Settings\n",
        "\n",
        "**<font color='#FF000'> IMPORTANT </font>**\n",
        "\n",
        "In the \"Runtime\" menu for the notebook window, select \"Change runtime type.\" Ensure that the following are selected:\n",
        "* Runtime Type = Python 3\n",
        "* Hardware Accelerator = GPU \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMZ2EAlBrvkq"
      },
      "source": [
        "#◢ Git clone\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69H2guBfrzqu",
        "outputId": "6d91c31e-04bd-4f21-ce82-3d876fd3cd68"
      },
      "source": [
        "!git clone https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life.git photo_restoration"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'photo_restoration'...\n",
            "remote: Enumerating objects: 493, done.\u001b[K\n",
            "remote: Counting objects: 100% (179/179), done.\u001b[K\n",
            "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
            "remote: Total 493 (delta 92), reused 120 (delta 62), pack-reused 314\u001b[K\n",
            "Receiving objects: 100% (493/493), 32.26 MiB | 47.88 MiB/s, done.\n",
            "Resolving deltas: 100% (208/208), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubc05fcKzk90"
      },
      "source": [
        "#◢ Set up the environment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32jCofdSr8AW",
        "outputId": "58e2ede5-e8b6-451d-f2f1-29e36923d7e7"
      },
      "source": [
        "# pull the syncBN repo\n",
        "%cd photo_restoration/Face_Enhancement/models/networks\n",
        "!git clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n",
        "!cp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\n",
        "%cd ../../../\n",
        "\n",
        "%cd Global/detection_models\n",
        "!git clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n",
        "!cp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\n",
        "%cd ../../\n",
        "\n",
        "# download the landmark detection model\n",
        "%cd Face_Detection/\n",
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bzip2 -d shape_predictor_68_face_landmarks.dat.bz2\n",
        "%cd ../\n",
        "\n",
        "# download the pretrained model\n",
        "%cd Face_Enhancement/\n",
        "!wget https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Face_Enhancement/checkpoints.zip\n",
        "!unzip checkpoints.zip\n",
        "%cd ../\n",
        "\n",
        "%cd Global/\n",
        "!wget https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Global/checkpoints.zip\n",
        "!unzip checkpoints.zip\n",
        "%cd ../"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/photo_restoration/Face_Enhancement/models/networks\n",
            "Cloning into 'Synchronized-BatchNorm-PyTorch'...\n",
            "remote: Enumerating objects: 188, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 188 (delta 10), reused 27 (delta 10), pack-reused 161\u001b[K\n",
            "Receiving objects: 100% (188/188), 47.20 KiB | 11.80 MiB/s, done.\n",
            "Resolving deltas: 100% (106/106), done.\n",
            "/content/photo_restoration\n",
            "/content/photo_restoration/Global/detection_models\n",
            "Cloning into 'Synchronized-BatchNorm-PyTorch'...\n",
            "remote: Enumerating objects: 188, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 188 (delta 10), reused 27 (delta 10), pack-reused 161\u001b[K\n",
            "Receiving objects: 100% (188/188), 47.20 KiB | 11.80 MiB/s, done.\n",
            "Resolving deltas: 100% (106/106), done.\n",
            "/content/photo_restoration\n",
            "/content/photo_restoration/Face_Detection\n",
            "--2022-01-23 19:25:32--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  69.0MB/s    in 0.9s    \n",
            "\n",
            "2022-01-23 19:25:33 (69.0 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n",
            "/content/photo_restoration\n",
            "/content/photo_restoration/Face_Enhancement\n",
            "--2022-01-23 19:25:40--  https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Face_Enhancement/checkpoints.zip\n",
            "Resolving facevc.blob.core.windows.net (facevc.blob.core.windows.net)... 20.60.68.132\n",
            "Connecting to facevc.blob.core.windows.net (facevc.blob.core.windows.net)|20.60.68.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 684354563 (653M) [application/x-zip-compressed]\n",
            "Saving to: ‘checkpoints.zip’\n",
            "\n",
            "checkpoints.zip     100%[===================>] 652.65M  16.0MB/s    in 39s     \n",
            "\n",
            "2022-01-23 19:26:19 (16.7 MB/s) - ‘checkpoints.zip’ saved [684354563/684354563]\n",
            "\n",
            "Archive:  checkpoints.zip\n",
            "   creating: checkpoints/\n",
            "   creating: checkpoints/Setting_9_epoch_100/\n",
            "  inflating: checkpoints/Setting_9_epoch_100/latest_net_G.pth  \n",
            "   creating: checkpoints/FaceSR_512/\n",
            "  inflating: checkpoints/FaceSR_512/latest_net_G.pth  \n",
            "/content/photo_restoration\n",
            "/content/photo_restoration/Global\n",
            "--2022-01-23 19:26:26--  https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Global/checkpoints.zip\n",
            "Resolving facevc.blob.core.windows.net (facevc.blob.core.windows.net)... 20.60.68.132\n",
            "Connecting to facevc.blob.core.windows.net (facevc.blob.core.windows.net)|20.60.68.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2036400762 (1.9G) [application/x-zip-compressed]\n",
            "Saving to: ‘checkpoints.zip’\n",
            "\n",
            "checkpoints.zip     100%[===================>]   1.90G  14.8MB/s    in 1m 58s  \n",
            "\n",
            "2022-01-23 19:28:24 (16.5 MB/s) - ‘checkpoints.zip’ saved [2036400762/2036400762]\n",
            "\n",
            "Archive:  checkpoints.zip\n",
            "   creating: checkpoints/\n",
            "   creating: checkpoints/restoration/\n",
            "   creating: checkpoints/restoration/VAE_B_scratch/\n",
            "  inflating: checkpoints/restoration/VAE_B_scratch/latest_net_G.pth  \n",
            "  inflating: checkpoints/restoration/VAE_B_scratch/latest_optimizer_G.pth  \n",
            "  inflating: checkpoints/restoration/VAE_B_scratch/latest_optimizer_D.pth  \n",
            "  inflating: checkpoints/restoration/VAE_B_scratch/latest_net_D.pth  \n",
            "   creating: checkpoints/restoration/VAE_A_quality/\n",
            "  inflating: checkpoints/restoration/VAE_A_quality/latest_net_G.pth  \n",
            "  inflating: checkpoints/restoration/VAE_A_quality/latest_net_featD.pth  \n",
            "  inflating: checkpoints/restoration/VAE_A_quality/latest_optimizer_G.pth  \n",
            "  inflating: checkpoints/restoration/VAE_A_quality/latest_optimizer_D.pth  \n",
            "  inflating: checkpoints/restoration/VAE_A_quality/latest_optimizer_featD.pth  \n",
            "  inflating: checkpoints/restoration/VAE_A_quality/latest_net_D.pth  \n",
            "   creating: checkpoints/restoration/mapping_Patch_Attention/\n",
            "  inflating: checkpoints/restoration/mapping_Patch_Attention/latest_net_mapping_net.pth  \n",
            "  inflating: checkpoints/restoration/mapping_Patch_Attention/latest_net_D.pth  \n",
            "   creating: checkpoints/restoration/mapping_quality/\n",
            "  inflating: checkpoints/restoration/mapping_quality/latest_net_mapping_net.pth  \n",
            "  inflating: checkpoints/restoration/mapping_quality/latest_optimizer_mapping_net.pth  \n",
            "  inflating: checkpoints/restoration/mapping_quality/latest_optimizer_D.pth  \n",
            "  inflating: checkpoints/restoration/mapping_quality/latest_net_D.pth  \n",
            "   creating: checkpoints/restoration/mapping_scratch/\n",
            "  inflating: checkpoints/restoration/mapping_scratch/latest_net_mapping_net.pth  \n",
            "  inflating: checkpoints/restoration/mapping_scratch/latest_optimizer_mapping_net.pth  \n",
            "  inflating: checkpoints/restoration/mapping_scratch/latest_optimizer_D.pth  \n",
            "  inflating: checkpoints/restoration/mapping_scratch/latest_net_D.pth  \n",
            "   creating: checkpoints/restoration/VAE_B_quality/\n",
            "  inflating: checkpoints/restoration/VAE_B_quality/latest_net_G.pth  \n",
            "  inflating: checkpoints/restoration/VAE_B_quality/latest_optimizer_G.pth  \n",
            "  inflating: checkpoints/restoration/VAE_B_quality/latest_optimizer_D.pth  \n",
            "  inflating: checkpoints/restoration/VAE_B_quality/latest_net_D.pth  \n",
            "   creating: checkpoints/detection/\n",
            "  inflating: checkpoints/detection/FT_Epoch_latest.pt  \n",
            "/content/photo_restoration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3v8tvmtw85c",
        "outputId": "20b3d788-7907-4c20-f65f-8254a5c14a33"
      },
      "source": [
        "! pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.11.1+cu111)\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (19.18.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.18.3)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.9)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (3.13)\n",
            "Collecting dominate>=2.3.1\n",
            "  Downloading dominate-2.6.0-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (0.3.4)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 47.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (4.1.2.30)\n",
            "Collecting einops\n",
            "  Downloading einops-0.4.0-py3-none-any.whl (28 kB)\n",
            "Collecting PySimpleGUI\n",
            "  Downloading PySimpleGUI-4.56.0-py3-none-any.whl (396 kB)\n",
            "\u001b[K     |████████████████████████████████| 396 kB 68.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 1)) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->-r requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 4)) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 4)) (2.6.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 4)) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 4)) (3.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->-r requirements.txt (line 9)) (3.17.3)\n",
            "Installing collected packages: tensorboardX, PySimpleGUI, einops, dominate\n",
            "Successfully installed PySimpleGUI-4.56.0 dominate-2.6.0 einops-0.4.0 tensorboardX-2.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soHBzgRU8rPY"
      },
      "source": [
        "#◢ Run the code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVpoONmCcJDt"
      },
      "source": [
        "### Restore photos (normal mode)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6lNy6jw5rjd",
        "outputId": "d2efad6c-7e16-4250-8003-ad76d5950270"
      },
      "source": [
        "%cd /content/photo_restoration/\n",
        "input_folder = \"test_images/old\"\n",
        "output_folder = \"output\"\n",
        "\n",
        "import os\n",
        "basepath = os.getcwd()\n",
        "input_path = os.path.join(basepath, input_folder)\n",
        "output_path = os.path.join(basepath, output_folder)\n",
        "os.mkdir(output_path)\n",
        "\n",
        "!python run.py --input_folder /content/photo_restoration/test_images/old --output_folder /content/photo_restoration/output/ --GPU 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/photo_restoration\n",
            "Running Stage 1: Overall restoration\n",
            "Mapping: You are using the mapping model without global restoration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yeeDiM4exHz"
      },
      "source": [
        "import io\n",
        "import IPython.display\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "\n",
        "def imshow(a, format='png', jpeg_fallback=True):\n",
        "    a = np.asarray(a, dtype=np.uint8)\n",
        "    data = io.BytesIO()\n",
        "    PIL.Image.fromarray(a).save(data, format)\n",
        "    im_data = data.getvalue()\n",
        "    try:\n",
        "      disp = IPython.display.display(IPython.display.Image(im_data))\n",
        "    except IOError:\n",
        "      if jpeg_fallback and format != 'jpeg':\n",
        "        print(('Warning: image was too large to display in format \"{}\"; '\n",
        "              'trying jpeg instead.').format(format))\n",
        "        return imshow(a, format='jpeg')\n",
        "      else:\n",
        "        raise\n",
        "    return disp\n",
        "\n",
        "def make_grid(I1, I2, resize=True):\n",
        "    I1 = np.asarray(I1)\n",
        "    H, W = I1.shape[0], I1.shape[1]\n",
        "    \n",
        "    if I1.ndim >= 3:\n",
        "        I2 = np.asarray(I2.resize((W,H)))\n",
        "        I_combine = np.zeros((H,W*2,3))\n",
        "        I_combine[:,:W,:] = I1[:,:,:3]\n",
        "        I_combine[:,W:,:] = I2[:,:,:3]\n",
        "    else:\n",
        "        I2 = np.asarray(I2.resize((W,H)).convert('L'))\n",
        "        I_combine = np.zeros((H,W*2))\n",
        "        I_combine[:,:W] = I1[:,:]\n",
        "        I_combine[:,W:] = I2[:,:]\n",
        "    I_combine = PIL.Image.fromarray(np.uint8(I_combine))\n",
        "\n",
        "    W_base = 600\n",
        "    if resize:\n",
        "      ratio = W_base / (W*2)\n",
        "      H_new = int(H * ratio)\n",
        "      I_combine = I_combine.resize((W_base, H_new), PIL.Image.LANCZOS)\n",
        "\n",
        "    return I_combine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_Eo4Hjti7Nh"
      },
      "source": [
        "filenames = os.listdir(os.path.join(input_path))\n",
        "filenames.sort()\n",
        "\n",
        "for filename in filenames:\n",
        "    print(filename)\n",
        "    image_original = PIL.Image.open(os.path.join(input_path, filename))\n",
        "    image_restore = PIL.Image.open(os.path.join(output_path, 'final_output', filename))\n",
        "\n",
        "    display(make_grid(image_original, image_restore))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSUF96UgTuwd"
      },
      "source": [
        "### Restore the photos with scratches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-yb3lO5T8aM"
      },
      "source": [
        "!rm -rf /content/photo_restoration/output/*\n",
        "!python run.py --input_folder /content/photo_restoration/test_images/old_w_scratch/ --output_folder /content/photo_restoration/output/ --GPU 0 --with_scratch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSSORPEMUSH0"
      },
      "source": [
        "input_folder = \"test_images/old_w_scratch\"\n",
        "output_folder = \"output\"\n",
        "input_path = os.path.join(basepath, input_folder)\n",
        "output_path = os.path.join(basepath, output_folder)\n",
        "\n",
        "filenames = os.listdir(os.path.join(input_path))\n",
        "filenames.sort()\n",
        "\n",
        "for filename in filenames:\n",
        "    print(filename)\n",
        "    image_original = PIL.Image.open(os.path.join(input_path, filename))\n",
        "    image_restore = PIL.Image.open(os.path.join(output_path, 'final_output', filename))\n",
        "\n",
        "    display(make_grid(image_original, image_restore))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMnje_NWj24x"
      },
      "source": [
        "#◢ Try it on your own photos!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vov9hg957-D"
      },
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "upload_path = os.path.join(basepath, \"test_images\", \"upload\")\n",
        "upload_output_path = os.path.join(basepath, \"upload_output\")\n",
        "\n",
        "if os.path.isdir(upload_output_path):\n",
        "    shutil.rmtree(upload_output_path)\n",
        "\n",
        "if os.path.isdir(upload_path):\n",
        "    shutil.rmtree(upload_path)\n",
        "\n",
        "os.mkdir(upload_output_path)\n",
        "os.mkdir(upload_path)\n",
        "\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    shutil.move(os.path.join(basepath, filename), os.path.join(upload_path, filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy9vSWTHMH5U"
      },
      "source": [
        "Run the processing with:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgRUwTqsjr7m"
      },
      "source": [
        "!python run.py --input_folder /content/photo_restoration/test_images/upload --output_folder /content/photo_restoration/upload_output --GPU 0 --with_scratch --HR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lEXtwXpLl1L"
      },
      "source": [
        "### Visualize\n",
        "\n",
        "Now you have all your results under the folder `upload_output` and you can *manually* right click and download them.\n",
        "\n",
        "Here we use the child photos of celebrities from https://www.boredpanda.com/childhood-celebrities-when-they-were-young-kids/?utm_source=google&utm_medium=organic&utm_campaign=organic "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvqDOPXnLmkl"
      },
      "source": [
        "filenames_upload = os.listdir(os.path.join(upload_path))\n",
        "filenames_upload.sort()\n",
        "\n",
        "filenames_upload_output = os.listdir(os.path.join(upload_output_path, \"final_output\"))\n",
        "filenames_upload_output.sort()\n",
        "\n",
        "for filename, filename_output in zip(filenames_upload, filenames_upload_output):\n",
        "    image_original = PIL.Image.open(os.path.join(upload_path, filename))\n",
        "    image_restore = PIL.Image.open(os.path.join(upload_output_path, \"final_output\", filename_output))\n",
        "\n",
        "    display(make_grid(image_original, image_restore))\n",
        "    print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2B75ztFYnnK"
      },
      "source": [
        "## Download your results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pJxB6p1R1jE"
      },
      "source": [
        "output_folder = os.path.join(upload_output_path, \"final_output\")\n",
        "print(output_folder)\n",
        "os.system(f\"zip -r -j download.zip {output_folder}/*\")\n",
        "files.download(\"download.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdFXuH9qd5u9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}